{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab591f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6111c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('Comments Corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "comment_lengths = comments['0'].str.len()\n",
    "plt.hist(comment_lengths, bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Comment Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Comment Lengths')\n",
    "plt.grid(axis='y', linestyle='-', alpha=0.7)\n",
    "plt.grid(axis='x', linestyle='-', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_length_histogram(text):\n",
    "    word_lengths = text.str.split().apply(lambda x: [len(i) for i in x])\n",
    "    mean_word_lengths = word_lengths.map(lambda x: np.mean(x))\n",
    "    plt.hist(mean_word_lengths, bins=20, color='green', alpha=0.7)\n",
    "    plt.xlabel('Mean Word Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Mean Word Lengths')\n",
    "    plt.grid(axis='y', linestyle='-', alpha=0.7)\n",
    "    plt.grid(axis='x', linestyle='-', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4de609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_length_histogram(comments['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "new = comments['0'].str.split()\n",
    "new = new.values.tolist()\n",
    "corpus= [word for i in new for word in i]\n",
    "\n",
    "from collections import defaultdict\n",
    "dic = defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(dic):\n",
    "    top = sorted(dic.items(), key = lambda x: x[1] , reverse = True)[:10]\n",
    "    x , y = zip(*top)\n",
    "    plt.bar(x , y)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Top 10 most frequent words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79046c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_hist(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6674226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "counter = Counter(corpus)\n",
    "most = counter.most_common()\n",
    "\n",
    "x , y = [], []\n",
    "for word, count in most[:40]:\n",
    "    \n",
    "    if(word not in stop):\n",
    "        \n",
    "        y.append(word)\n",
    "        x.append(count)\n",
    "\n",
    "# sns.barplot(x = x , y = y)\n",
    "# plt.xlabel('Frequency')\n",
    "# plt.title('most frequent words after removing stop words')\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(x=x, y=y)\n",
    "plt.xlabel('Frequency', fontsize=14)\n",
    "plt.ylabel('Words', fontsize=14)\n",
    "plt.title('Most Frequent Words after Removing Stop Words', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c86919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def get_top_ngram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx])\n",
    "                  for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_bigrams=get_top_ngram(comments['0'],2)[:10]\n",
    "x,y = map(list,zip(*top_n_bigrams)) \n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(x=y, y=x)\n",
    "plt.xlabel('Frequency', fontsize=14)\n",
    "plt.title('Top bi-grams', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tri_grams = get_top_ngram(comments['0'] , n = 3)\n",
    "y,x = map(list , zip(*top_tri_grams))\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(x=x, y=y)\n",
    "plt.xlabel('Frequency', fontsize=14)\n",
    "plt.title('Top tri-grams', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720841f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.stem.wordnet import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess(df):\n",
    "    \n",
    "    corpus = []\n",
    "    stem = PorterStemmer()\n",
    "    lem = WordNetLemmatizer()\n",
    "    \n",
    "    for comment in df['0']:\n",
    "        \n",
    "        words = [w for w in word_tokenize(comment) if (w not in stop)]\n",
    "        words = [lem.lemmatize(w) for w in words if (len(w) > 2)]\n",
    "        corpus.append(words)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bcd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocess(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a880518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "dic = gensim.corpora.Dictionary(corpus)\n",
    "bow_corpus = [dic.doc2bow(comm) for comm in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddf6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus,\n",
    "                                   num_topics = 4,\n",
    "                                   id2word = dic,\n",
    "                                   passes = 10,\n",
    "                                   workers = 2)\n",
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb22c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dic)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a413e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9974b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035da7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Diu was liberated from Portuguese rule by the Indian government in 1961\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x.text , x.label_) for x in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12260830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc , style = \"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    return [x.label_ for x in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = comments['0'].apply(lambda x: ner(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944494d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_map = {}\n",
    "for sub in ent:\n",
    "    for ner_type in sub:\n",
    "        if(ner_type not in ner_map): ner_map[ner_type] = 0\n",
    "        ner_map[ner_type]+= 1\n",
    "ner_map = sorted(ner_map.items() , key = lambda x: x[1] , reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ff5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y , x = map(list , zip(*ner_map))\n",
    "sns.barplot(x = x , y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffe304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ner(text , ent):\n",
    "    doc = nlp(text)\n",
    "    return [x.text for x in doc.ents if x.label_ == ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpe = comments['0'].apply(lambda x: get_top_ner(x , \"GPE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa902a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpe_map = {}\n",
    "for sub in gpe:\n",
    "    for name in sub:\n",
    "        if(name not in gpe_map): gpe_map[name] = 0\n",
    "        gpe_map[name]+= 1\n",
    "gpe_map = sorted(gpe_map.items() , key = lambda x: x[1] , reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y , x = map(list , zip(*gpe_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca48018",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = x , y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd53b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
